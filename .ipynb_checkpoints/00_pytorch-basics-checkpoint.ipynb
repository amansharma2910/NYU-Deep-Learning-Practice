{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Basics\n",
    "---\n",
    "## Importing the Project Dependencies\n",
    "---\n",
    "\n",
    "The first step of a project is to import all the necessary dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let us set the default device as the CUDA GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have successfully set the GPU as the default computational device for the tensors. The advantage of using GPU is that several tensors can be worked upon in parallel, hence increasing the processing speeds by several folds.\n",
    "\n",
    "Now let us have a look at how to create and perform some elementary operations on tensors in PyTorch. \n",
    "\n",
    "## Tensors\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.7092e-04, 4.1428e-11, 1.7474e-04, 2.9574e-18],\n",
       "         [6.7333e+22, 1.7591e+22, 1.7184e+25, 4.3222e+27],\n",
       "         [6.1972e-04, 7.2443e+22, 1.7728e+28, 7.0367e+22]],\n",
       "\n",
       "        [[1.8704e+20, 3.2944e-09, 1.3086e-11, 4.1545e+21],\n",
       "         [6.7377e-10, 6.6756e+22, 6.3082e-10, 3.2686e+21],\n",
       "         [2.7447e-06, 2.4830e-18, 7.7052e+31, 1.9447e+31]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generating a tensor of dimensions 2x3x4\n",
    "t = torch.Tensor(2,3,4)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4])\n",
      "torch.Size([2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "# checking the shape of the tensor\n",
    "print(t.size())\n",
    "print(t.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While both .size() and .shape return the same values, the only difference between these two is that .size() is a method while on the other hand .shape is an attribute of a tensor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of elements within the tensor = 2 × 3 × 4 = 24\n",
      "Number of dimensions in the tensor = 3\n"
     ]
    }
   ],
   "source": [
    "# number of elements in a tensor- numel() method\n",
    "print('Total number of elements within the tensor =', \n",
    "      ' \\u00D7 '.join(map(str, t.shape)), '=', t.numel())\n",
    "\n",
    "# number of dimensions that make up the tensor- dim() method\n",
    "print('Number of dimensions in the tensor =', t.dim())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us have a look at some of the tensor mutations. Tensor mutations are special methods that modify/mutate a tensor in-place. The mutation methods are post-fixed by an underscore at the end. Let us see some examples here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[4., 7., 4., 5.],\n",
       "         [1., 7., 9., 2.],\n",
       "         [8., 6., 6., 7.]],\n",
       "\n",
       "        [[3., 0., 2., 3.],\n",
       "         [4., 2., 2., 4.],\n",
       "         [5., 8., 3., 3.]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# .random_(n) - Replaces the values within a tensor w/ integersbetween range [0-n)\n",
    "t.random_(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[4., 7., 4., 5.],\n",
       "         [1., 7., 9., 2.],\n",
       "         [8., 6., 6., 7.]],\n",
       "\n",
       "        [[3., 0., 2., 3.],\n",
       "         [4., 2., 2., 4.],\n",
       "         [5., 8., 3., 3.]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# .copy_(x) - Makes a copy of the tensor into another tensor x\n",
    "y = torch.empty_like(t).copy_(t)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[4., 7., 4.],\n",
       "         [5., 1., 7.]],\n",
       "\n",
       "        [[9., 2., 8.],\n",
       "         [6., 6., 7.]],\n",
       "\n",
       "        [[3., 0., 2.],\n",
       "         [3., 4., 2.]],\n",
       "\n",
       "        [[2., 4., 5.],\n",
       "         [8., 3., 3.]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# .resize_() - Used to reshape the tensor \n",
    "y.resize_(4,2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# .zero_() - Replaces all tensor elements with 0s\n",
    "y.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[5., 5., 5.],\n",
       "         [5., 5., 5.]],\n",
       "\n",
       "        [[5., 5., 5.],\n",
       "         [5., 5., 5.]],\n",
       "\n",
       "        [[5., 5., 5.],\n",
       "         [5., 5., 5.]],\n",
       "\n",
       "        [[5., 5., 5.],\n",
       "         [5., 5., 5.]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# .fill_() - Used to replace all the tensor values with the fill argument value\n",
    "y.fill_(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have seen some of the important mutation methods, let us have a look at one of the most important operations while working with tensors- Cloning a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[5., 5., 5.],\n",
       "         [5., 5., 5.]],\n",
       "\n",
       "        [[5., 5., 5.],\n",
       "         [5., 5., 5.]],\n",
       "\n",
       "        [[5., 5., 5.],\n",
       "         [5., 5., 5.]],\n",
       "\n",
       "        [[5., 5., 5.],\n",
       "         [5., 5., 5.]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = y.detach().clone()\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectors and Matrices\n",
    "---\n",
    "\n",
    "In this section, we are going to have a look at some of the general operations that we get to perform frequently while working with vectors and matrices in PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a = tensor([1., 2., 3., 4., 5.])\n",
      "b = tensor([5., 2., 7., 1., 0.])\n"
     ]
    }
   ],
   "source": [
    "# creating a vector\n",
    "a = torch.Tensor([1, 2, 3, 4, 5])\n",
    "b = torch.Tensor([5, 2, 7, 1, 0,])\n",
    "\n",
    "print('a =', a)\n",
    "print('b =', b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5.,  4., 21.,  4.,  0.])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# performing element-wise mutliplication\n",
    "a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(34.)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scalar product of the vectors, i.e., sum(a_i * b_i)\n",
    "a @ b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0000,  6.5809, 19.8130, 43.3081, 79.4324])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vector exponentiation- (a_i)^x\n",
    "a.pow(np.e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case of indexing, the tensors in PyTorch follow the same standard as seen in NumPy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 5., 3., 7.],\n",
       "        [4., 2., 1., 9.],\n",
       "        [6., 1., 8., 4.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a 2x3x4 tensor\n",
    "m = torch.Tensor([[2, 5, 3, 7],\n",
    "                  [4, 2, 1, 9],\n",
    "                  [6, 1, 8, 4]])\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of dimensions = 2\n",
      "Shape of tensor matrix = torch.Size([3, 4])\n",
      "Total number of elements = 12\n"
     ]
    }
   ],
   "source": [
    "# checking the dimensions of the matrix\n",
    "print('No. of dimensions =', m.dim())\n",
    "\n",
    "# checking the shape of the matric\n",
    "print('Shape of tensor matrix =', m.shape)\n",
    "\n",
    "# number of elements within the matrix\n",
    "print('Total number of elements =', m.numel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[m]3,2 = tensor(1.)\n",
      "[m]1->2, 1->3 = tensor([[2., 5., 3.],\n",
      "        [4., 2., 1.]])\n",
      "tensor([5., 2., 1.])\n",
      "tensor([[5.],\n",
      "        [2.],\n",
      "        [1.]])\n"
     ]
    }
   ],
   "source": [
    "## indexing in tensors\n",
    "\n",
    "# element in 3rd row, 2nd column\n",
    "print('[m]3,2 =', m[2, 1])\n",
    "# NOTE- The indexing operation returns a 0D tensor in this case\n",
    "\n",
    "print('[m]1->2, 1->3 =', m[:2, :3]) \n",
    "\n",
    "print(m[:, 1])\n",
    "print(m[:, [1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us have a look at multiplication of matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.arange(1,12+1).reshape(3,4).type(torch.FloatTensor)\n",
    "n = torch.Tensor([[2, 5, 3, 7],\n",
    "                  [4, 2, 1, 9],\n",
    "                  [6, 1, 8, 4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2., 10.,  9., 28.],\n",
       "        [20., 12.,  7., 72.],\n",
       "        [54., 10., 88., 48.]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# element-wise product of 2 matrices\n",
    "m * n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 49., 117., 185.],\n",
       "        [ 47., 111., 175.],\n",
       "        [ 48., 124., 200.]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scalar product of 2 matrices (a.k.a. matrix multiplication)\n",
    "n @ m.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us move forward to the next section where we will have a look at some of the other useful tensor operations.\n",
    "\n",
    "## Misc. Tensor Operations\n",
    "---\n",
    "\n",
    "First let us have a look at the various ways we can typecast a tensor. This is important since most binary operations on tensors requires the tensors to be of the same type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The various types of Tensors in PyTorch are:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.BFloat16Tensor\n",
       "torch.BoolTensor\n",
       "torch.ByteTensor\n",
       "torch.CharTensor\n",
       "torch.DoubleTensor\n",
       "torch.FloatTensor\n",
       "torch.HalfTensor\n",
       "torch.IntTensor\n",
       "torch.LongTensor\n",
       "torch.ShortTensor\n",
       "torch.Tensor"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# helper function to check the various tensor types in PyTorch\n",
    "print('The various types of Tensors in PyTorch are:\\n')\n",
    "torch.*Tensor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.FloatTensor'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the type of a tensor\n",
    "m.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2,  3,  4],\n",
       "        [ 5,  6,  7,  8],\n",
       "        [ 9, 10, 11, 12]], dtype=torch.int32)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting 'm' to an integer tensor\n",
    "m.type(torch.IntTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True],\n",
       "        [True, True, True, True],\n",
       "        [True, True, True, True]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting 'm' to boolean tensor \n",
    "m.type(torch.BoolTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.,  3.,  4.],\n",
       "        [ 5.,  6.,  7.,  8.],\n",
       "        [ 9., 10., 11., 12.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting the tensor to type double\n",
    "m.double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  2.,  3.,  4.],\n",
       "       [ 5.,  6.,  7.,  8.],\n",
       "       [ 9., 10., 11., 12.]], dtype=float32)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting the tensor to a numpy array\n",
    "n = m.numpy()\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available device:  cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.,  3.,  4.],\n",
       "        [ 5.,  6.,  7.,  8.],\n",
       "        [ 9., 10., 11., 12.]], device='cuda:0')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# moving a tensor to GPU/ converting a tensor to CUDA tensor\n",
    "print('Available device: ',device)\n",
    "m = m.to(device)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.,  3.,  4.],\n",
       "        [ 5.,  6.,  7.,  8.],\n",
       "        [ 9., 10., 11., 12.]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# moving a tensor back to cpu\n",
    "m = m.to('cpu')\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Moving a tensor to-an-fro from the CPU to the CUDA device takes up some temporary space within the memory and hence is a memory intensive process. So refrain from moving the tensors to-and-fro between devices again and again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.,  3.,  4.],\n",
       "        [ 5.,  6.,  7.,  8.],\n",
       "        [ 9., 10., 11., 12.]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting a numpy array into a tensor\n",
    "x = torch.from_numpy(n)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this, we have completed most of the basic PyTorch operations that we will be frequenting during the course."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
