{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Algebra with PyTorch\n",
    "---\n",
    "\n",
    "Let us begin by importing the necessary modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determinant of a matrix: \n",
    "The determinant of matrix is calculated using the __torch.linalg.det()__ function. One thing to be noted is that the function accepts only a float matrix. Also, you can calculate the determinant of a square matrix only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[19., 13.,  9., 11.],\n",
      "        [ 9., 19.,  8., 17.],\n",
      "        [12., 12.,  7., 10.],\n",
      "        [17., 16., 10.,  6.]], dtype=torch.float64)\n",
      "tensor(-338.0000, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# determinant of a matrix\n",
    "a = torch.randint(20, (4, 4)).double()\n",
    "print(a)\n",
    "print(torch.linalg.det(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inverse of a matrix:\n",
    "\n",
    "The torch.inverse() function is used to calculate the inverse of a matrix. One thing to be noted is that not every matrix is invertible. In case you try to invert a singular matrix (determinant = 0), you will end up with a run time error. \n",
    "\n",
    "Hence, checking if a matrix is singular is a good exception handling method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1099, -0.1697, -0.0205,  0.0194],\n",
      "        [ 0.0471, -0.1016, -0.0718,  0.0797],\n",
      "        [-0.0728,  0.0560,  0.0723, -0.0098],\n",
      "        [-0.0033,  0.1307,  0.0019, -0.0229]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "a = torch.randint(20, (4, 4)).double()\n",
    "if torch.linalg.det(a):\n",
    "    print(torch.inverse(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "inverse_cpu: U(3,3) is zero, singular U.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m-------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-7a4af144619f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m                   \u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                   [0,0,0]])\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: inverse_cpu: U(3,3) is zero, singular U."
     ]
    }
   ],
   "source": [
    "# will result in an error as matrix 'b' is singular\n",
    "\n",
    "b = torch.Tensor([[1,2,3],\n",
    "                  [2,3,4],\n",
    "                  [0,0,0]])\n",
    "torch.inverse(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Norms:\n",
    "\n",
    "The torch.linalg.norm() method is used to calculate the various types of norms of matrices and vectors.\n",
    "\n",
    "Here are some of the most used norms within linear algebra.\n",
    "\n",
    "* __L<sup>2</sup> norm__: Used to calculate the distance of a vector from the origin.\n",
    "\n",
    "* __L<sup>1</sup> norm__: The L1 norm is used is used when the difference between zero and non-zero elements is very important. The value of the L1 norm increases *e* when the vector moves away from the origin by a value *e*.\n",
    "\n",
    "* __L<sup>0</sup> norm__: The L0 norm is used to calculate the number of non-zero elements within a vector.\n",
    "\n",
    "* __Infinity norm__: The infinity norm is used to calculate the maximum element within the vector. Similarly, the -infinity norm is used to calculate the value of the minimum element within the vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = torch.Tensor([3, 4, 1, 2, 0, 6, 3, 0, 5, 9, 0])\n",
    "print('L2 norm =', torch.linalg.norm(v, ord = 2))\n",
    "print('L1 norm =', torch.linalg.norm(v, ord = 1))\n",
    "print('L0 norm =', torch.linalg.norm(v, ord = 0))\n",
    "print('Inf norm =', torch.linalg.norm(v, ord = float('inf')))\n",
    "print('-Inf norm =', torch.linalg.norm(v, ord = -float('inf')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eignedecomposition:\n",
    "\n",
    "### → A v = λ v  \n",
    "\n",
    "Eigendecomposition can be used to decompose a given square matrix into eigenvalues and eigenvectors. Doing so allows us to analyze certain properties of the matrix that otherwise might not be visible to the practitioner at the first glance of the data matrix.  \n",
    "\n",
    "Here are some of the properties of eigendecomposition:\n",
    "\n",
    "* Any real symmetric matrix is guaranteed to have an eigendecomposition. However, the eigendecomposition might not be unique. The eigendecomposition is said to be unique only and only if all the eigenvalues are unique.\n",
    "\n",
    "* If any of the eigenavlues are 0, then the matrix is a singular matrix.\n",
    "\n",
    "* In case of positive semidefinite matrices (all eigenvalues either positive or 0), __x<sup>T</sup> A x >= 0__.\n",
    "\n",
    "* In case of positive definite matrices, __x<sup>T</sup> A x = 0__.\n",
    "\n",
    "Now, let us have a look at how to perform eigendecomposition using PyTorch. \n",
    "\n",
    "NOTE: \n",
    "> * Eigendecomposition is possible only for square matrices.\n",
    "> * Regular eigendecomposition (torch.eig()) can return complex eigenvectors and eigenvalues. Hence, backpropagation is not possible in case of torch.eig. Use __torch.symeig()__ to be able to perform backpropagation on eigenvectors. Symmetric eigendecomposition is carried out for real, symmetric matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# square asymmetric matrix\n",
    "a = torch.Tensor([[1, 6, 5, 4],\n",
    "                  [7, 3, 2, 1],\n",
    "                  [3, 8, 9, 6],\n",
    "                  [4, 5, 6, 7]])\n",
    "\n",
    "# square symmetric matrix\n",
    "b = torch.Tensor([[1, 2, 3, 4, 5],\n",
    "                  [2, 3, 4, 5, 6],\n",
    "                  [3, 4, 5, 6, 7],\n",
    "                  [4, 5, 6, 7, 8],\n",
    "                  [5, 6, 7, 8, 9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvalues = tensor([[19.3617,  0.0000],\n",
      "        [-3.7889,  0.0000],\n",
      "        [ 1.5183,  0.0000],\n",
      "        [ 2.9089,  0.0000]])\n",
      "Eigenvectors = tensor([[ 0.3973,  0.6052, -0.0843, -0.1020],\n",
      "        [ 0.2857, -0.7128, -0.3329, -0.5572],\n",
      "        [ 0.6634,  0.3440,  0.7931, -0.0292],\n",
      "        [ 0.5661, -0.0853, -0.5030,  0.8236]])\n"
     ]
    }
   ],
   "source": [
    "# regular eigendecomposition\n",
    "eig_val, eig_vect = torch.eig(a, eigenvectors=True)\n",
    "print('Eigenvalues =', eig_val)\n",
    "print('Eigenvectors =', eig_vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing to be noted is that in case of regular eigendecomposition, the eigenvalue is a __n x 2__ matrix. The first column of the matrices represents the real part of each eigenvalue, and the second column represents the imaginary part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvalues = tensor([-1.8614e+00, -4.6570e-07,  4.4451e-08,  6.4121e-07,  2.6861e+01])\n",
      "Eigenvectors = tensor([[ 0.7255,  0.4651,  0.0324, -0.4273,  0.2715],\n",
      "        [ 0.4197, -0.5476,  0.5069,  0.3784,  0.3520],\n",
      "        [ 0.1138, -0.3923, -0.8036, -0.0198,  0.4325],\n",
      "        [-0.1920,  0.5669, -0.0429,  0.6138,  0.5130],\n",
      "        [-0.4978, -0.0922,  0.3073, -0.5451,  0.5935]])\n"
     ]
    }
   ],
   "source": [
    "# symmetric eigendecomposition\n",
    "symeig_val, symeig_vect = torch.symeig(b, eigenvectors=True)\n",
    "print('Eigenvalues =', eig_val)\n",
    "print('Eigenvectors =', eig_vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Singular Value Decomposition:\n",
    "\n",
    "### → A<sub>m x n</sub> = U<sub>m x m</sub> D<sub>m x n</sub> V<sub>n x n</sub>\n",
    "\n",
    "As Prof. Gilbert Strang said, SVD is one of the most important equations in linear algebra. Built on the same idea as eigendecomposition, SVD addresses one major issue with eigendecomposition. \n",
    "\n",
    "> Eigendecomposition is only applicable to square matrices. Also, you get real eigenvalues only for non-singular matrices. \n",
    "\n",
    "> SVD on the other hand allows decomposition of rectangular matrices as well. And unlike eigendecomposition, SVD is possible for every matrix. \n",
    "\n",
    "Let us have a look at how to perform SVD using PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6.,  5., 12., 16., 12.,  3.],\n",
      "        [15.,  4.,  4.,  4., 13., 10.],\n",
      "        [10.,  2.,  0.,  7.,  8.,  7.],\n",
      "        [13., 13.,  2.,  6., 13., 13.]], dtype=torch.float64)\n",
      "\n",
      "Left singular vector =\n",
      " tensor([[-0.4880,  0.8680,  0.0713, -0.0571],\n",
      "        [-0.5226, -0.2856, -0.5606, -0.5754],\n",
      "        [-0.3628, -0.1143, -0.4391,  0.8140],\n",
      "        [-0.5976, -0.3897,  0.6985,  0.0556]], dtype=torch.float64)\n",
      "\n",
      "Singular values =\n",
      " tensor([42.8254, 15.3217,  7.2010,  4.1690], dtype=torch.float64)\n",
      "\n",
      "Right singular vector =\n",
      " tensor([[-0.5175, -0.3041, -0.2135, -0.3742, -0.5446, -0.3969],\n",
      "        [-0.3450, -0.1369,  0.5544,  0.6271,  0.0472, -0.3993],\n",
      "        [-0.4570,  0.8772,  0.0014,  0.0022, -0.1200,  0.0854],\n",
      "        [-0.0267, -0.0566, -0.6899,  0.6754, -0.2233,  0.1189]],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# 4 x 6 matrix of floats\n",
    "A = torch.randint(20, (4, 6)).double()\n",
    "\n",
    "U, D, V = torch.svd(A)\n",
    "\n",
    "print(A)\n",
    "print('\\nLeft singular vector =\\n', U)\n",
    "print('\\nSingular values =\\n', D)\n",
    "print('\\nRight singular vector =\\n', V.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6.0000e+00, 5.0000e+00, 1.2000e+01, 1.6000e+01, 1.2000e+01, 3.0000e+00],\n",
       "        [1.5000e+01, 4.0000e+00, 4.0000e+00, 4.0000e+00, 1.3000e+01, 1.0000e+01],\n",
       "        [1.0000e+01, 2.0000e+00, 1.8787e-15, 7.0000e+00, 8.0000e+00, 7.0000e+00],\n",
       "        [1.3000e+01, 1.3000e+01, 2.0000e+00, 6.0000e+00, 1.3000e+01, 1.3000e+01]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_regenerated = torch.mm(torch.mm(U, torch.diag(D)), V.t())\n",
    "A_regenerated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
